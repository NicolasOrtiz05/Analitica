{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicolasOrtiz05/Analitica/blob/main/practica2_edwingutro_nicolasorco_carloszulmor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N48aBRWyTpK"
      },
      "source": [
        "# Práctica 1: Ambiente Snake y Agente Reactivo\n",
        "### Analítica de Datos\n",
        "### Universidad de La Sabana\n",
        "\n",
        "---\n",
        "\n",
        "**Fecha límite de entrega**: Miércoles 14 de agosto antes de la medianoche (ver instrucciones en Teams).\n",
        "\n",
        "\n",
        "Cerciórese de reiniciar y correr el notebook en su totalidad antes de enviarlo. Verifique que todas las salidas se muestran de manera correcta.\n",
        "\n",
        "Integrantes del grupo (máximo 3):\n",
        "\n",
        "* Edwin Alejandro Gutierrez - edwingutro\n",
        "* Nicolas Stiven Ortiz Cortes - nicolasorco\n",
        "* Carlos Zuluaga Mora - carloszulmor\n",
        "\n",
        "---\n",
        "\n",
        "Las siguientes instrucciones instalan las librerías y archivos necesarios para el notebook. Si ejecuta el notebook en un entorno local, verifique las direcciones estén bien."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnvmmfOjyTpL",
        "outputId": "cc31fda5-83af-4f35-e869-97ddce3fa553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'snake-ai-reinforcement': No such file or directory\n",
            "Cloning into 'snake-ai-reinforcement'...\n",
            "remote: Enumerating objects: 197, done.\u001b[K\n",
            "remote: Total 197 (delta 0), reused 0 (delta 0), pack-reused 197 (from 1)\u001b[K\n",
            "Receiving objects: 100% (197/197), 42.98 KiB | 800.00 KiB/s, done.\n",
            "Resolving deltas: 100% (97/97), done.\n",
            "sample_data  snakeai  snake-ai-reinforcement\n"
          ]
        }
      ],
      "source": [
        "!rm -r snake-ai-reinforcement # Elimina (rm: remove) cualquier cosa que se llame igual y que de casualidad tenga ud en la misma carpeta del notebook\n",
        "!git clone https://github.com/YuriyGuts/snake-ai-reinforcement.git # Clona el repositorio de github en cuestion (git clone)\n",
        "!mv snake-ai-reinforcement/snakeai . # Mueve (mv: move) la carpeta /snake al mismo directorio del notebook\n",
        "!ls # lista (ls: list) el contenido del directorio donde está el notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRhDrrGyyTpO"
      },
      "source": [
        "Vamos a construir un agente que sea capaz de jugar el juego de *Snake*:\n",
        "\n",
        "<img src=\"https://cloud.githubusercontent.com/assets/2750531/24808769/cc825424-1bc5-11e7-816f-7320f7bda2cf.gif\" alt=\"Snake snapshot\" width=\"320\"/>\n",
        "\n",
        "Para esto vamos a usar como base este [proyecto](https://github.com/YuriyGuts/snake-ai-reinforcement) desarrollado por [Yuriy Guts](https://github.com/YuriyGuts).\n",
        "\n",
        "Primero definimos una clase que nos permite simular el juego:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJWDk5OSyTpP"
      },
      "outputs": [],
      "source": [
        "from snakeai.gameplay.environment import Environment\n",
        "\n",
        "class EnvironmentPO(Environment):\n",
        "    \"\"\"\n",
        "    Partial observation environment. Same as base class environment, overloads\n",
        "    `get_observation` so that only the cells in front of the snake are returned.\n",
        "    (From Environment doc): Represents the RL environment for the Snake game that implements the game logic,\n",
        "    provides rewards for the agent and keeps track of game statistics.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, verbose=0):\n",
        "        super().__init__(config, verbose)\n",
        "\n",
        "    @property\n",
        "    def observation_shape(self):\n",
        "        \"\"\" Get the shape of the state observed at each timestep. \"\"\"\n",
        "        return 3\n",
        "\n",
        "    def get_observation(self):\n",
        "        \"\"\" Observe the state of the environment. \"\"\"\n",
        "        if self.is_game_over:\n",
        "            return (0, 0, 0)\n",
        "        center = self.snake.head + self.snake.direction\n",
        "        if self.snake.direction == Point(0,1):\n",
        "            left = self.snake.head + Point(1,0)\n",
        "            right = self.snake.head + Point(-1, 0)\n",
        "        elif self.snake.direction == Point(0, -1):\n",
        "            left = self.snake.head + Point(-1, 0)\n",
        "            right = self.snake.head + Point(1, 0)\n",
        "        elif self.snake.direction == Point(1, 0):\n",
        "            left = self.snake.head + Point(0, -1)\n",
        "            right = self.snake.head + Point(0, 1)\n",
        "        else:\n",
        "            left = self.snake.head + Point(0, 1)\n",
        "            right = self.snake.head + Point(0, -1)\n",
        "        return (self.field[left], self.field[center], self.field[right])\n",
        "\n",
        "    def show_field(self):\n",
        "        return self.field.__str__()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5agS4a53yTpR"
      },
      "source": [
        "Esta clase extiende la clase `Environment` del proyecto `snakeai`:\n",
        "\n",
        "```Python\n",
        "class Environment(object):\n",
        "    \"\"\"\n",
        "    Represents the RL environment for the Snake game that implements the game logic,\n",
        "    provides rewards for the agent and keeps track of game statistics.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, verbose=1):\n",
        "        \"\"\"\n",
        "        Create a new Snake RL environment.\n",
        "        \n",
        "        Args:\n",
        "            config (dict): level configuration, typically found in JSON configs.  \n",
        "            verbose (int): verbosity level:\n",
        "                0 = do not write any debug information;\n",
        "                1 = write a CSV file containing the statistics for every episode;\n",
        "                2 = same as 1, but also write a full log file containing the state of each timestep.\n",
        "        \"\"\"\n",
        "        self.field = Field(level_map=config['field'])\n",
        "        self.snake = None\n",
        "        self.fruit = None\n",
        "        self.initial_snake_length = config['initial_snake_length']\n",
        "        self.rewards = config['rewards']\n",
        "        self.max_step_limit = config.get('max_step_limit', 1000)\n",
        "        self.is_game_over = False\n",
        "\n",
        "        self.timestep_index = 0\n",
        "        self.current_action = None\n",
        "        self.stats = EpisodeStatistics()\n",
        "        self.verbose = verbose\n",
        "        self.debug_file = None\n",
        "        self.stats_file = None\n",
        "\n",
        "    def seed(self, value):\n",
        "\n",
        "    @property\n",
        "    def observation_shape(self):\n",
        "        \"\"\" Get the shape of the state observed at each timestep. \"\"\"\n",
        "\n",
        "    @property\n",
        "    def num_actions(self):\n",
        "        \"\"\" Get the number of actions the agent can take. \"\"\"\n",
        "\n",
        "    def new_episode(self):\n",
        "        \"\"\" Reset the environment and begin a new episode. \"\"\"\n",
        "        \n",
        "    def record_timestep_stats(self, result):\n",
        "        \"\"\" Record environment statistics according to the verbosity level. \"\"\"\n",
        "\n",
        "    def get_observation(self):\n",
        "        \"\"\" Observe the state of the environment. \"\"\"\n",
        "\n",
        "    def choose_action(self, action):\n",
        "        \"\"\" Choose the action that will be taken at the next timestep. \"\"\"\n",
        "\n",
        "    def timestep(self):\n",
        "        \"\"\" Execute the timestep and return the new observable state. \"\"\"\n",
        "\n",
        "    def generate_fruit(self, position=None):\n",
        "        \"\"\" Generate a new fruit at a random unoccupied cell. \"\"\"\n",
        "\n",
        "    def has_hit_wall(self):\n",
        "        \"\"\" True if the snake has hit a wall, False otherwise. \"\"\"\n",
        "\n",
        "    def has_hit_own_body(self):\n",
        "        \"\"\" True if the snake has hit its own body, False otherwise. \"\"\"\n",
        "\n",
        "    def is_alive(self):\n",
        "        \"\"\" True if the snake is still alive, False otherwise. \"\"\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RnHlJBDyTpS"
      },
      "source": [
        "Un agente para jugar Snake lo construimos extendiendo la clase `AgentBase`. El siguiente es un agente que ejecuta sus acciones al azar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW-q09_zyTpT"
      },
      "outputs": [],
      "source": [
        "from snakeai.agent import AgentBase\n",
        "\n",
        "class RandomActionAgent(AgentBase):\n",
        "    \"\"\" Represents a Snake agent that takes a random action at every step. \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def begin_episode(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, observation, reward):\n",
        "        return random.choice(ALL_SNAKE_ACTIONS)\n",
        "\n",
        "    def end_episode(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86vPsfhvyTpV"
      },
      "source": [
        "Finalmente definimos una función `play` que nos permite simular el juego:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjsuf6h-yTpV"
      },
      "outputs": [],
      "source": [
        "from snakeai.gameplay.entities import ALL_SNAKE_ACTIONS, Point\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "def play(env, agent, num_episodes=1, verbose=1):\n",
        "    \"\"\"\n",
        "    Play a set of episodes using the specified Snake agent.\n",
        "    Use the non-interactive command-line interface and print the summary statistics afterwards.\n",
        "\n",
        "    Args:\n",
        "        env: an instance of Snake environment.\n",
        "        agent: an instance of Snake agent.\n",
        "        num_episodes (int): the number of episodes to run.\n",
        "    \"\"\"\n",
        "\n",
        "    fruit_stats = []\n",
        "\n",
        "    print()\n",
        "    print('Playing:')\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        timestep = env.new_episode()\n",
        "        agent.begin_episode()\n",
        "        game_over = False\n",
        "        step = 0\n",
        "        while not game_over:\n",
        "\n",
        "            if verbose > 0:\n",
        "                print(\"------ Step \", step, \" ------\")\n",
        "                print (env.show_field())\n",
        "                print (\"Observation:\", env.get_observation())\n",
        "                print (\"Head:\", env.snake.head)\n",
        "                print (\"Direction:\", env.snake.direction)\n",
        "\n",
        "            step += 1\n",
        "            action = agent.act(timestep.observation, timestep.reward)\n",
        "            env.choose_action(action)\n",
        "            timestep = env.timestep()\n",
        "            game_over = timestep.is_episode_end\n",
        "\n",
        "        fruit_stats.append(env.stats.fruits_eaten)\n",
        "\n",
        "        summary = '******* Episode {:3d} / {:3d} | Timesteps {:4d} | Fruits {:2d}'\n",
        "        print(summary.format(episode + 1, num_episodes, env.stats.timesteps_survived, env.stats.fruits_eaten))\n",
        "\n",
        "    print()\n",
        "    print('Fruits eaten {:.1f} +/- stddev {:.1f}'.format(np.mean(fruit_stats), np.std(fruit_stats)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IggythB8yTpX"
      },
      "source": [
        "Ya tenemos todos los elementos necesarios para simular el juego. Arrancamos con un tablero inicial en el cual\n",
        "la serpiente está en el centro. Esto lo especificamos con un dictionario que indica la configuración, los campos\n",
        "que nos interesan son `field`, `initial_snake_length` y `max_step_limit`, los otros campo los podemo ignorar por el momento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9VKVGquyTpY"
      },
      "outputs": [],
      "source": [
        "inicial = {\n",
        "  \"field\": [\n",
        "    \"#######\",\n",
        "    \"#.....#\",\n",
        "    \"#.....#\",\n",
        "    \"#..S..#\",\n",
        "    \"#.....#\",\n",
        "    \"#.....#\",\n",
        "    \"#######\"\n",
        "  ],\n",
        "\n",
        "  \"initial_snake_length\": 2,\n",
        "  \"max_step_limit\": 100,\n",
        "\n",
        "  \"rewards\": {\n",
        "    \"timestep\": -0.01,\n",
        "    \"ate_fruit\": 1,\n",
        "    \"died\": -1\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFSfH6koyTpa"
      },
      "source": [
        "Veamos como se comporta el agente aleatorio con esta configuración:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq6SeINpyTpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98453078-0530-4b9c-ec60-09bdfd514e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Playing:\n",
            "------ Step  0  ------\n",
            "#######\n",
            "#.....#\n",
            "#.###.#\n",
            "#..S.O#\n",
            "#..s..#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (0, 4, 0)\n",
            "Head: Point(x=3, y=3)\n",
            "Direction: Point(x=0, y=-1)\n",
            "------ Step  1  ------\n",
            "#######\n",
            "#.....#\n",
            "#.###.#\n",
            "#.Ss.O#\n",
            "#.....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (0, 0, 4)\n",
            "Head: Point(x=2, y=3)\n",
            "Direction: Point(x=-1, y=0)\n",
            "------ Step  2  ------\n",
            "#######\n",
            "#.....#\n",
            "#.###.#\n",
            "#Ss..O#\n",
            "#.....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (0, 4, 0)\n",
            "Head: Point(x=1, y=3)\n",
            "Direction: Point(x=-1, y=0)\n",
            "------ Step  3  ------\n",
            "#######\n",
            "#.....#\n",
            "#S###.#\n",
            "#s...O#\n",
            "#.....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (4, 0, 4)\n",
            "Head: Point(x=1, y=2)\n",
            "Direction: Point(x=0, y=-1)\n",
            "------ Step  4  ------\n",
            "#######\n",
            "#S....#\n",
            "#s###.#\n",
            "#....O#\n",
            "#.....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (4, 4, 0)\n",
            "Head: Point(x=1, y=1)\n",
            "Direction: Point(x=0, y=-1)\n",
            "******* Episode   1 /   1 | Timesteps    5 | Fruits  0\n",
            "\n",
            "Fruits eaten 0.0 +/- stddev 0.0\n"
          ]
        }
      ],
      "source": [
        "env = EnvironmentPO(config=inicial, verbose=0)\n",
        "agent = RandomActionAgent()\n",
        "play(env, agent, num_episodes= 1, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2XDwmdYBpX5"
      },
      "source": [
        "## 1. Agente con un plan determinado\n",
        "\n",
        "Vamos a construir un agente que partiendo del siguiente estado inicial:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhJB1-QFyTpg"
      },
      "outputs": [],
      "source": [
        "```\n",
        "#######\n",
        "#.....#\n",
        "#.###.#\n",
        "#..S..#\n",
        "##.s..#\n",
        "#.....#\n",
        "#######\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-UMr3bgDB6f"
      },
      "source": [
        "llegue al siguiente estado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYt-BNH4DHhY"
      },
      "outputs": [],
      "source": [
        "```\n",
        "#######\n",
        "#.....#\n",
        "#s###.#\n",
        "#S....#\n",
        "##....#\n",
        "#.....#\n",
        "#######\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu1LsjNbDQ6Q"
      },
      "outputs": [],
      "source": [
        "from snakeai.gameplay.entities import SnakeAction\n",
        "class PredefinedActionAgent(AgentBase):\n",
        "    \"\"\" Represents a Snake agent that takes a random action at every step. \"\"\"\n",
        "\n",
        "    def __init__(self, actions):\n",
        "        self.actions = actions\n",
        "        self.step = 0\n",
        "        pass\n",
        "\n",
        "    def begin_episode(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, observation, reward):\n",
        "        \"\"\"\n",
        "        The agent takes the next action in the list of actions. Increases\n",
        "        step by 1.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.step < len(self.actions):\n",
        "            action = self.actions[self.step]\n",
        "            self.step += 1\n",
        "        else:\n",
        "            action = SnakeAction.MAINTAIN_DIRECTION\n",
        "\n",
        "\n",
        "        # Your code here\n",
        "\n",
        "        return action\n",
        "\n",
        "    def end_episode(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fx_QtZNcZuRR",
        "outputId": "3c45dd41-65d7-4681-e661-1fdbedc2b1f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Playing:\n",
            "------ Step  0  ------\n",
            "#######\n",
            "#.....#\n",
            "#.###O#\n",
            "#..S..#\n",
            "##.s..#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (0, 4, 0)\n",
            "Head: Point(x=3, y=3)\n",
            "Direction: Point(x=0, y=-1)\n",
            "------ Step  1  ------\n",
            "#######\n",
            "#.....#\n",
            "#.###O#\n",
            "#..sS.#\n",
            "##....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (4, 0, 0)\n",
            "Head: Point(x=4, y=3)\n",
            "Direction: Point(x=1, y=0)\n",
            "------ Step  2  ------\n",
            "#######\n",
            "#.....#\n",
            "#.###O#\n",
            "#...sS#\n",
            "##....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (1, 4, 0)\n",
            "Head: Point(x=5, y=3)\n",
            "Direction: Point(x=1, y=0)\n",
            "------ Step  3  ------\n",
            "#######\n",
            "#.....#\n",
            "#O###S#\n",
            "#...ss#\n",
            "##....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (4, 0, 4)\n",
            "Head: Point(x=5, y=2)\n",
            "Direction: Point(x=0, y=-1)\n",
            "------ Step  4  ------\n",
            "#######\n",
            "#....S#\n",
            "#O###s#\n",
            "#....s#\n",
            "##....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (0, 4, 4)\n",
            "Head: Point(x=5, y=1)\n",
            "Direction: Point(x=0, y=-1)\n",
            "------ Step  5  ------\n",
            "#######\n",
            "#...Ss#\n",
            "#O###s#\n",
            "#.....#\n",
            "##....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (4, 0, 4)\n",
            "Head: Point(x=4, y=1)\n",
            "Direction: Point(x=-1, y=0)\n",
            "------ Step  6  ------\n",
            "#######\n",
            "#..Sss#\n",
            "#O###.#\n",
            "#.....#\n",
            "##....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (4, 0, 4)\n",
            "Head: Point(x=3, y=1)\n",
            "Direction: Point(x=-1, y=0)\n",
            "------ Step  7  ------\n",
            "#######\n",
            "#.Sss.#\n",
            "#O###.#\n",
            "#.....#\n",
            "##....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (4, 0, 4)\n",
            "Head: Point(x=2, y=1)\n",
            "Direction: Point(x=-1, y=0)\n",
            "------ Step  8  ------\n",
            "#######\n",
            "#Sss..#\n",
            "#O###.#\n",
            "#.....#\n",
            "##....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (1, 4, 4)\n",
            "Head: Point(x=1, y=1)\n",
            "Direction: Point(x=-1, y=0)\n",
            "------ Step  9  ------\n",
            "#######\n",
            "#sss..#\n",
            "#S###.#\n",
            "#....O#\n",
            "##....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (4, 0, 4)\n",
            "Head: Point(x=1, y=2)\n",
            "Direction: Point(x=0, y=1)\n",
            "------ Step  10  ------\n",
            "#######\n",
            "#ss...#\n",
            "#s###.#\n",
            "#S...O#\n",
            "##....#\n",
            "#.....#\n",
            "#######\n",
            "Observation: (0, 4, 4)\n",
            "Head: Point(x=1, y=3)\n",
            "Direction: Point(x=0, y=1)\n",
            "******* Episode   1 /   1 | Timesteps   11 | Fruits  2\n",
            "\n",
            "Fruits eaten 2.0 +/- stddev 0.0\n"
          ]
        }
      ],
      "source": [
        "from snakeai.gameplay.entities import SnakeAction\n",
        "inicial1 = inicial = {\n",
        "  \"field\": [\n",
        "    \"#######\",\n",
        "    \"#.....#\",\n",
        "    \"#.###.#\",\n",
        "    \"#..S..#\",\n",
        "    \"##.s..#\",\n",
        "    \"#.....#\",\n",
        "    \"#######\"\n",
        "  ],\n",
        "\n",
        "  \"initial_snake_length\": 2,\n",
        "  \"max_step_limit\": 1000,\n",
        "\n",
        "  \"rewards\": {\n",
        "    \"timestep\": -0.01,\n",
        "    \"ate_fruit\": 1,\n",
        "    \"died\": -1\n",
        "  }\n",
        "}\n",
        "\n",
        "env = EnvironmentPO(config=inicial1, verbose=1)\n",
        "agent = PredefinedActionAgent([\n",
        "    SnakeAction.TURN_RIGHT,\n",
        "    SnakeAction.MAINTAIN_DIRECTION,\n",
        "    SnakeAction.TURN_LEFT,\n",
        "    SnakeAction.MAINTAIN_DIRECTION,\n",
        "    SnakeAction.TURN_LEFT,\n",
        "    SnakeAction.MAINTAIN_DIRECTION,\n",
        "    SnakeAction.MAINTAIN_DIRECTION,\n",
        "    SnakeAction.MAINTAIN_DIRECTION,\n",
        "    SnakeAction.TURN_LEFT,\n",
        "    SnakeAction.MAINTAIN_DIRECTION\n",
        "])\n",
        "play(env, agent, num_episodes= 1, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I855jFzUE0Rf"
      },
      "source": [
        "## 2. Agente reactivo\n",
        "\n",
        "La idea es construir un agente reactivo, es decir que sus acciones solo dependen de la observación en un momento dado y\n",
        "no tiene memoria. El agente debe procurar no estrellarse y come cuantas frutas pueda. Compare el comportamiento de este agente con el del agente\n",
        "al azar. Simule cada agente por 100 episodios. Presente los resultados y discútalos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "flQ8qda5fCC9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsfEGgp3FwAU"
      },
      "outputs": [],
      "source": [
        "from snakeai.agent import AgentBase\n",
        "from snakeai.gameplay.entities import SnakeAction, CellType\n",
        "\n",
        "class ReactiveAgent(AgentBase):\n",
        "    \"\"\"\n",
        "    Represents a reactive Snake agent that dcides an action exclusively based on\n",
        "    the current observation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def begin_episode(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, observation, reward):\n",
        "        \"\"\"\n",
        "        The agent anlizes de current observation and takes a consequent action.\n",
        "        \"\"\"\n",
        "        # Your code here\n",
        "        left, front, right = observation\n",
        "\n",
        "        if front == CellType.FRUIT:\n",
        "            return SnakeAction.MAINTAIN_DIRECTION\n",
        "        elif left == CellType.FRUIT:\n",
        "            return SnakeAction.TURN_LEFT\n",
        "        elif right == CellType.FRUIT:\n",
        "            return SnakeAction.TURN_RIGHT\n",
        "\n",
        "        else:\n",
        "            valid_actions = []\n",
        "            if front not in (CellType.WALL, CellType.SNAKE_BODY):\n",
        "                valid_actions.append(SnakeAction.MAINTAIN_DIRECTION)\n",
        "            if left not in (CellType.WALL, CellType.SNAKE_BODY):\n",
        "                valid_actions.append(SnakeAction.TURN_LEFT)\n",
        "            if right not in (CellType.WALL, CellType.SNAKE_BODY):\n",
        "                valid_actions.append(SnakeAction.TURN_RIGHT)\n",
        "\n",
        "            if not valid_actions:\n",
        "                valid_actions = ALL_SNAKE_ACTIONS\n",
        "\n",
        "            return random.choice(valid_actions)\n",
        "    def end_episode(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcionamiento agente reactivo\n",
        "from snakeai.gameplay.entities import SnakeAction\n",
        "inicial2 = inicial = {\n",
        "  \"field\": [\n",
        "    \"#######\",\n",
        "    \"#.....#\",\n",
        "    \"#.###.#\",\n",
        "    \"#..S..#\",\n",
        "    \"#..s..#\",\n",
        "    \"#.....#\",\n",
        "    \"#######\"\n",
        "  ],\n",
        "\n",
        "  \"initial_snake_length\": 2,\n",
        "  \"max_step_limit\": 100,\n",
        "\n",
        "  \"rewards\": {\n",
        "    \"timestep\": -0.01,\n",
        "    \"ate_fruit\": 1,\n",
        "    \"died\": -1\n",
        "  }\n",
        "}\n",
        "\n",
        "env = EnvironmentPO(config=inicial2, verbose=1)\n",
        "agent = ReactiveAgent()\n",
        "play(env, agent, num_episodes= 1, verbose=1)"
      ],
      "metadata": {
        "id": "jtx4g7USe4DY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora con una nueva funcion podemos comparar cuantas frutas come el agente\n"
      ],
      "metadata": {
        "id": "eIwyrz0UdR4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from snakeai.gameplay.entities import Point\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def play_com(env, agent_random, agent_reactivo, num_episodes=100, verbose=1):\n",
        "    fruit_stats_random = []\n",
        "    fruit_stats_reactivo = []\n",
        "    timesteps_random = []\n",
        "    timesteps_reactivo = []\n",
        "\n",
        "    print()\n",
        "    print('Playing:')\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        # Agente aleatorio\n",
        "        timestep = env.new_episode()\n",
        "        agent_random.begin_episode()\n",
        "        game_over = False\n",
        "        steps = 0\n",
        "        while not game_over:\n",
        "            steps += 1\n",
        "            action = agent_random.act(timestep.observation, timestep.reward)\n",
        "            env.choose_action(action)\n",
        "            timestep = env.timestep()\n",
        "            game_over = timestep.is_episode_end\n",
        "\n",
        "        fruit_stats_random.append(env.stats.fruits_eaten)\n",
        "        timesteps_random.append(steps)\n",
        "\n",
        "        # Agente reactivo\n",
        "        timestep = env.new_episode()\n",
        "        agent_reactivo.begin_episode()\n",
        "        game_over = False\n",
        "        steps = 0\n",
        "        while not game_over:\n",
        "            steps += 1\n",
        "            action = agent_reactivo.act(timestep.observation, timestep.reward)\n",
        "            env.choose_action(action)\n",
        "            timestep = env.timestep()\n",
        "            game_over = timestep.is_episode_end\n",
        "\n",
        "        fruit_stats_reactivo.append(env.stats.fruits_eaten)\n",
        "        timesteps_reactivo.append(steps)\n",
        "\n",
        "        if verbose:\n",
        "            summary = ('******* Episode {:3d} / {:3d} | '\n",
        "                       'Timesteps Random {:4d} | Fruits Random {:2d} | '\n",
        "                       'Timesteps Reactivo {:4d} | Fruits Reactivo {:2d}')\n",
        "            print(summary.format(episode + 1, num_episodes,\n",
        "                                 timesteps_random[-1], fruit_stats_random[-1],\n",
        "                                 timesteps_reactivo[-1], fruit_stats_reactivo[-1]))\n",
        "\n",
        "    if verbose:\n",
        "        print()\n",
        "        print('Average fruits eaten by Random Agent: {:.1f} +/- stddev {:.1f}'.format(\n",
        "            np.mean(fruit_stats_random), np.std(fruit_stats_random)))\n",
        "        print('Average fruits eaten by Reactive Agent: {:.1f} +/- stddev {:.1f}'.format(\n",
        "            np.mean(fruit_stats_reactivo), np.std(fruit_stats_reactivo)))\n",
        "        print('Average timesteps for Random Agent: {:.1f} +/- stddev {:.1f}'.format(\n",
        "            np.mean(timesteps_random), np.std(timesteps_random)))\n",
        "        print('Average timesteps for Reactive Agent: {:.1f} +/- stddev {:.1f}'.format(\n",
        "            np.mean(timesteps_reactivo), np.std(timesteps_reactivo)))\n"
      ],
      "metadata": {
        "id": "4RjetxCyjUoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from snakeai.gameplay.entities import SnakeAction\n",
        "inicial3 = {\n",
        "  \"field\": [\n",
        "    \"#######\",\n",
        "    \"#.....#\",\n",
        "    \"#.....#\",\n",
        "    \"#..S..#\",\n",
        "    \"#..s..#\",\n",
        "    \"#.....#\",\n",
        "    \"#######\"\n",
        "  ],\n",
        "\n",
        "  \"initial_snake_length\": 2,\n",
        "  \"max_step_limit\": 100,\n",
        "\n",
        "  \"rewards\": {\n",
        "    \"timestep\": -0.01,\n",
        "    \"ate_fruit\": 1,\n",
        "    \"died\": -1\n",
        "  }\n",
        "}\n",
        "\n",
        "env = EnvironmentPO(config=inicial3, verbose=0)\n",
        "agent_reactivo = ReactiveAgent()\n",
        "agent_random = RandomActionAgent()\n",
        "play_com(env, agent_random, agent_reactivo, num_episodes=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCAVmRwxeAc-",
        "outputId": "eeab0d06-9d07-4205-9878-182bf2aa68f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Playing:\n",
            "******* Episode   1 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   52 | Fruits Reactivo  5\n",
            "******* Episode   2 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   40 | Fruits Reactivo  6\n",
            "******* Episode   3 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   34 | Fruits Reactivo  7\n",
            "******* Episode   4 / 100 | Timesteps Random    3 | Fruits Random  0 | Timesteps Reactivo  100 | Fruits Reactivo  3\n",
            "******* Episode   5 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   45 | Fruits Reactivo  7\n",
            "******* Episode   6 / 100 | Timesteps Random   14 | Fruits Random  0 | Timesteps Reactivo  100 | Fruits Reactivo  5\n",
            "******* Episode   7 / 100 | Timesteps Random   13 | Fruits Random  0 | Timesteps Reactivo   32 | Fruits Reactivo  8\n",
            "******* Episode   8 / 100 | Timesteps Random    9 | Fruits Random  0 | Timesteps Reactivo   17 | Fruits Reactivo  4\n",
            "******* Episode   9 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   69 | Fruits Reactivo  7\n",
            "******* Episode  10 / 100 | Timesteps Random    6 | Fruits Random  1 | Timesteps Reactivo   75 | Fruits Reactivo  8\n",
            "******* Episode  11 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   53 | Fruits Reactivo  5\n",
            "******* Episode  12 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   83 | Fruits Reactivo  7\n",
            "******* Episode  13 / 100 | Timesteps Random    7 | Fruits Random  0 | Timesteps Reactivo   49 | Fruits Reactivo  5\n",
            "******* Episode  14 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   66 | Fruits Reactivo  5\n",
            "******* Episode  15 / 100 | Timesteps Random    3 | Fruits Random  0 | Timesteps Reactivo   19 | Fruits Reactivo  2\n",
            "******* Episode  16 / 100 | Timesteps Random   14 | Fruits Random  2 | Timesteps Reactivo   11 | Fruits Reactivo  2\n",
            "******* Episode  17 / 100 | Timesteps Random    9 | Fruits Random  1 | Timesteps Reactivo   57 | Fruits Reactivo  6\n",
            "******* Episode  18 / 100 | Timesteps Random    4 | Fruits Random  1 | Timesteps Reactivo   51 | Fruits Reactivo  2\n",
            "******* Episode  19 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   13 | Fruits Reactivo  3\n",
            "******* Episode  20 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   93 | Fruits Reactivo  7\n",
            "******* Episode  21 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   84 | Fruits Reactivo  6\n",
            "******* Episode  22 / 100 | Timesteps Random    7 | Fruits Random  0 | Timesteps Reactivo   86 | Fruits Reactivo  9\n",
            "******* Episode  23 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   81 | Fruits Reactivo 10\n",
            "******* Episode  24 / 100 | Timesteps Random    4 | Fruits Random  1 | Timesteps Reactivo  100 | Fruits Reactivo  8\n",
            "******* Episode  25 / 100 | Timesteps Random   11 | Fruits Random  1 | Timesteps Reactivo   65 | Fruits Reactivo  8\n",
            "******* Episode  26 / 100 | Timesteps Random   16 | Fruits Random  1 | Timesteps Reactivo  100 | Fruits Reactivo  9\n",
            "******* Episode  27 / 100 | Timesteps Random   10 | Fruits Random  0 | Timesteps Reactivo   47 | Fruits Reactivo  2\n",
            "******* Episode  28 / 100 | Timesteps Random   11 | Fruits Random  0 | Timesteps Reactivo   55 | Fruits Reactivo  7\n",
            "******* Episode  29 / 100 | Timesteps Random   21 | Fruits Random  1 | Timesteps Reactivo   17 | Fruits Reactivo  2\n",
            "******* Episode  30 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo  100 | Fruits Reactivo  9\n",
            "******* Episode  31 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   61 | Fruits Reactivo  4\n",
            "******* Episode  32 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo  100 | Fruits Reactivo  3\n",
            "******* Episode  33 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   81 | Fruits Reactivo  4\n",
            "******* Episode  34 / 100 | Timesteps Random    5 | Fruits Random  1 | Timesteps Reactivo   71 | Fruits Reactivo 10\n",
            "******* Episode  35 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   87 | Fruits Reactivo 11\n",
            "******* Episode  36 / 100 | Timesteps Random   11 | Fruits Random  0 | Timesteps Reactivo   52 | Fruits Reactivo  4\n",
            "******* Episode  37 / 100 | Timesteps Random    3 | Fruits Random  0 | Timesteps Reactivo   67 | Fruits Reactivo  8\n",
            "******* Episode  38 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   81 | Fruits Reactivo  7\n",
            "******* Episode  39 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   73 | Fruits Reactivo  6\n",
            "******* Episode  40 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   97 | Fruits Reactivo 11\n",
            "******* Episode  41 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   69 | Fruits Reactivo  8\n",
            "******* Episode  42 / 100 | Timesteps Random    4 | Fruits Random  1 | Timesteps Reactivo   41 | Fruits Reactivo  6\n",
            "******* Episode  43 / 100 | Timesteps Random   11 | Fruits Random  0 | Timesteps Reactivo  100 | Fruits Reactivo  6\n",
            "******* Episode  44 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   65 | Fruits Reactivo  8\n",
            "******* Episode  45 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   75 | Fruits Reactivo  9\n",
            "******* Episode  46 / 100 | Timesteps Random    9 | Fruits Random  0 | Timesteps Reactivo   73 | Fruits Reactivo  6\n",
            "******* Episode  47 / 100 | Timesteps Random    6 | Fruits Random  1 | Timesteps Reactivo   99 | Fruits Reactivo 11\n",
            "******* Episode  48 / 100 | Timesteps Random    6 | Fruits Random  0 | Timesteps Reactivo   63 | Fruits Reactivo 15\n",
            "******* Episode  49 / 100 | Timesteps Random   12 | Fruits Random  0 | Timesteps Reactivo   23 | Fruits Reactivo  2\n",
            "******* Episode  50 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   85 | Fruits Reactivo  9\n",
            "******* Episode  51 / 100 | Timesteps Random   10 | Fruits Random  1 | Timesteps Reactivo   85 | Fruits Reactivo 12\n",
            "******* Episode  52 / 100 | Timesteps Random    9 | Fruits Random  1 | Timesteps Reactivo   73 | Fruits Reactivo  8\n",
            "******* Episode  53 / 100 | Timesteps Random    9 | Fruits Random  1 | Timesteps Reactivo   57 | Fruits Reactivo  5\n",
            "******* Episode  54 / 100 | Timesteps Random    3 | Fruits Random  0 | Timesteps Reactivo  100 | Fruits Reactivo  5\n",
            "******* Episode  55 / 100 | Timesteps Random    5 | Fruits Random  1 | Timesteps Reactivo   87 | Fruits Reactivo  6\n",
            "******* Episode  56 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   85 | Fruits Reactivo  8\n",
            "******* Episode  57 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo  100 | Fruits Reactivo  7\n",
            "******* Episode  58 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   53 | Fruits Reactivo  7\n",
            "******* Episode  59 / 100 | Timesteps Random    3 | Fruits Random  0 | Timesteps Reactivo   48 | Fruits Reactivo  8\n",
            "******* Episode  60 / 100 | Timesteps Random    4 | Fruits Random  1 | Timesteps Reactivo   45 | Fruits Reactivo  4\n",
            "******* Episode  61 / 100 | Timesteps Random   10 | Fruits Random  2 | Timesteps Reactivo   62 | Fruits Reactivo  7\n",
            "******* Episode  62 / 100 | Timesteps Random    7 | Fruits Random  0 | Timesteps Reactivo   58 | Fruits Reactivo  4\n",
            "******* Episode  63 / 100 | Timesteps Random   13 | Fruits Random  0 | Timesteps Reactivo   61 | Fruits Reactivo  5\n",
            "******* Episode  64 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   29 | Fruits Reactivo  3\n",
            "******* Episode  65 / 100 | Timesteps Random    8 | Fruits Random  0 | Timesteps Reactivo   65 | Fruits Reactivo  6\n",
            "******* Episode  66 / 100 | Timesteps Random   19 | Fruits Random  0 | Timesteps Reactivo   79 | Fruits Reactivo  9\n",
            "******* Episode  67 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   65 | Fruits Reactivo  8\n",
            "******* Episode  68 / 100 | Timesteps Random    7 | Fruits Random  0 | Timesteps Reactivo   82 | Fruits Reactivo 11\n",
            "******* Episode  69 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo  100 | Fruits Reactivo  9\n",
            "******* Episode  70 / 100 | Timesteps Random   16 | Fruits Random  0 | Timesteps Reactivo   93 | Fruits Reactivo 10\n",
            "******* Episode  71 / 100 | Timesteps Random    3 | Fruits Random  0 | Timesteps Reactivo   27 | Fruits Reactivo  2\n",
            "******* Episode  72 / 100 | Timesteps Random   15 | Fruits Random  1 | Timesteps Reactivo  100 | Fruits Reactivo  5\n",
            "******* Episode  73 / 100 | Timesteps Random    4 | Fruits Random  1 | Timesteps Reactivo   71 | Fruits Reactivo  6\n",
            "******* Episode  74 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   45 | Fruits Reactivo  2\n",
            "******* Episode  75 / 100 | Timesteps Random    3 | Fruits Random  0 | Timesteps Reactivo   69 | Fruits Reactivo  4\n",
            "******* Episode  76 / 100 | Timesteps Random    3 | Fruits Random  0 | Timesteps Reactivo   61 | Fruits Reactivo  5\n",
            "******* Episode  77 / 100 | Timesteps Random    6 | Fruits Random  0 | Timesteps Reactivo   81 | Fruits Reactivo 13\n",
            "******* Episode  78 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   61 | Fruits Reactivo  6\n",
            "******* Episode  79 / 100 | Timesteps Random   14 | Fruits Random  1 | Timesteps Reactivo   39 | Fruits Reactivo  5\n",
            "******* Episode  80 / 100 | Timesteps Random    6 | Fruits Random  1 | Timesteps Reactivo  100 | Fruits Reactivo  7\n",
            "******* Episode  81 / 100 | Timesteps Random   10 | Fruits Random  0 | Timesteps Reactivo   31 | Fruits Reactivo  6\n",
            "******* Episode  82 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   69 | Fruits Reactivo  9\n",
            "******* Episode  83 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   89 | Fruits Reactivo  9\n",
            "******* Episode  84 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   85 | Fruits Reactivo  7\n",
            "******* Episode  85 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   57 | Fruits Reactivo  3\n",
            "******* Episode  86 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   71 | Fruits Reactivo  3\n",
            "******* Episode  87 / 100 | Timesteps Random    7 | Fruits Random  0 | Timesteps Reactivo   91 | Fruits Reactivo 13\n",
            "******* Episode  88 / 100 | Timesteps Random    3 | Fruits Random  0 | Timesteps Reactivo   39 | Fruits Reactivo  7\n",
            "******* Episode  89 / 100 | Timesteps Random    9 | Fruits Random  0 | Timesteps Reactivo   59 | Fruits Reactivo  4\n",
            "******* Episode  90 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   97 | Fruits Reactivo 10\n",
            "******* Episode  91 / 100 | Timesteps Random    7 | Fruits Random  0 | Timesteps Reactivo   68 | Fruits Reactivo  8\n",
            "******* Episode  92 / 100 | Timesteps Random    8 | Fruits Random  0 | Timesteps Reactivo   70 | Fruits Reactivo  9\n",
            "******* Episode  93 / 100 | Timesteps Random   10 | Fruits Random  0 | Timesteps Reactivo   26 | Fruits Reactivo  5\n",
            "******* Episode  94 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   58 | Fruits Reactivo  7\n",
            "******* Episode  95 / 100 | Timesteps Random    9 | Fruits Random  1 | Timesteps Reactivo   53 | Fruits Reactivo  4\n",
            "******* Episode  96 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   73 | Fruits Reactivo  7\n",
            "******* Episode  97 / 100 | Timesteps Random    4 | Fruits Random  0 | Timesteps Reactivo   43 | Fruits Reactivo  3\n",
            "******* Episode  98 / 100 | Timesteps Random    5 | Fruits Random  0 | Timesteps Reactivo   36 | Fruits Reactivo  5\n",
            "******* Episode  99 / 100 | Timesteps Random    8 | Fruits Random  1 | Timesteps Reactivo   66 | Fruits Reactivo  7\n",
            "******* Episode 100 / 100 | Timesteps Random    6 | Fruits Random  0 | Timesteps Reactivo   92 | Fruits Reactivo 14\n",
            "\n",
            "Average fruits eaten by Random Agent: 0.2 +/- stddev 0.5\n",
            "Average fruits eaten by Reactive Agent: 6.6 +/- stddev 2.8\n",
            "Average timesteps for Random Agent: 6.7 +/- stddev 3.8\n",
            "Average timesteps for Reactive Agent: 66.1 +/- stddev 23.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por tanto, podemos evidenciar que el agente reactivo recoge muchos más frutas que él random, probablemente esto se deba a que él random suele perder bastante fácil al no considerar los muros que se pueda encontrar, también el agente reactivo tiene como prioridad encontrar la fruta, lo que permite que a pesar de que sus movimientos se han aleatorios obtenga mayor puntaje."
      ],
      "metadata": {
        "id": "pWoS3TGpK9Iu"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}